{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# read in S3 credentials from ./.aws/credentials file\n",
    "# assumes we are using a credential profile names 'dev'\n",
    "session = boto3.Session(profile_name='dev')\n",
    "s3_client = session.client('s3')\n",
    "# change this to the bucket you want to read/write to:\n",
    "s3_bucket = 'drb-estuary-salinity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write from a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file version: WSymHRVvZhDELGYs_ycyoKpkH619xf60\n"
     ]
    }
   ],
   "source": [
    "# define the location of the file you want to upload to S3\n",
    "local_fpath = './data/usgs_nwis_01477050.csv'\n",
    "# definte the location within the S3 bucket where you want to save this file\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "# upload your file\n",
    "response = s3_client.put_object(Body=open(local_fpath, 'rb'), Bucket=s3_bucket, Key=s3_fpath)\n",
    "# retrieve the version number\n",
    "version_fromfile = response.get(\"ResponseMetadata\").get('HTTPHeaders').get('x-amz-version-id')\n",
    "print(f'file version: {version_fromfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write from pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>121609_00010</th>\n",
       "      <th>121607_00095</th>\n",
       "      <th>121610_00300</th>\n",
       "      <th>121612_00301</th>\n",
       "      <th>121608_00400</th>\n",
       "      <th>243095_99133</th>\n",
       "      <th>243094_99134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>8.822222</td>\n",
       "      <td>316.944444</td>\n",
       "      <td>11.289189</td>\n",
       "      <td>97.361111</td>\n",
       "      <td>7.557576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>8.543750</td>\n",
       "      <td>314.114583</td>\n",
       "      <td>11.205208</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.506250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>8.834375</td>\n",
       "      <td>313.635417</td>\n",
       "      <td>11.206250</td>\n",
       "      <td>96.677083</td>\n",
       "      <td>7.519792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>9.365625</td>\n",
       "      <td>311.552083</td>\n",
       "      <td>11.161458</td>\n",
       "      <td>97.552083</td>\n",
       "      <td>7.503125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>9.278022</td>\n",
       "      <td>307.648352</td>\n",
       "      <td>11.161538</td>\n",
       "      <td>97.318681</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime  121609_00010  121607_00095  121610_00300  121612_00301  \\\n",
       "0  2019-04-01      8.822222    316.944444     11.289189     97.361111   \n",
       "1  2019-04-02      8.543750    314.114583     11.205208     96.000000   \n",
       "2  2019-04-03      8.834375    313.635417     11.206250     96.677083   \n",
       "3  2019-04-04      9.365625    311.552083     11.161458     97.552083   \n",
       "4  2019-04-05      9.278022    307.648352     11.161538     97.318681   \n",
       "\n",
       "   121608_00400  243095_99133  243094_99134  \n",
       "0      7.557576           NaN           NaN  \n",
       "1      7.506250           NaN           NaN  \n",
       "2      7.519792           NaN           NaN  \n",
       "3      7.503125           NaN           NaN  \n",
       "4      7.500000           NaN           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in a dataset as a pandas df use as an example\n",
    "local_fpath = './data/usgs_nwis_01477050.csv'\n",
    "df = pd.read_csv(local_fpath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file version: CPVYosH_Y3XI5hEo2h8zQEW7Tdp_ODzB\n"
     ]
    }
   ],
   "source": [
    "# definte the location within the S3 bucket where you want to save this file\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromdf.csv'\n",
    "# upload your file\n",
    "with io.StringIO() as csv_buffer:\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    response = s3_client.put_object(Bucket=s3_bucket, Key=s3_fpath, Body=csv_buffer.getvalue())\n",
    "# retrieve the version number\n",
    "version_fromdf = response.get(\"ResponseMetadata\").get('HTTPHeaders').get('x-amz-version-id')\n",
    "print(f'file version: {version_fromdf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List files in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_shared_data/\n",
      "00_shared_data/usgs_nwis_01477050_fromdf.csv\n",
      "00_shared_data/usgs_nwis_01477050_fromfile.csv\n"
     ]
    }
   ],
   "source": [
    "# define a file prefix to look in your bucket for\n",
    "prefix = '00_shared_data'\n",
    "# loop through all objects with this prefix and print\n",
    "for obj in s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=prefix)['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and save to a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file in S3 bucket that you want to retrieve\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "# definte the local file path that you want to save this file to\n",
    "local_fpath = './data/usgs_nwis_01477050_downloaded.csv'\n",
    "# download the data file\n",
    "s3_client.download_file(s3_bucket, s3_fpath, local_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>121609_00010</th>\n",
       "      <th>121607_00095</th>\n",
       "      <th>121610_00300</th>\n",
       "      <th>121612_00301</th>\n",
       "      <th>121608_00400</th>\n",
       "      <th>243095_99133</th>\n",
       "      <th>243094_99134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>8.822222</td>\n",
       "      <td>316.944444</td>\n",
       "      <td>11.289189</td>\n",
       "      <td>97.361111</td>\n",
       "      <td>7.557576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>8.543750</td>\n",
       "      <td>314.114583</td>\n",
       "      <td>11.205208</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.506250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>8.834375</td>\n",
       "      <td>313.635417</td>\n",
       "      <td>11.206250</td>\n",
       "      <td>96.677083</td>\n",
       "      <td>7.519792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>9.365625</td>\n",
       "      <td>311.552083</td>\n",
       "      <td>11.161458</td>\n",
       "      <td>97.552083</td>\n",
       "      <td>7.503125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>9.278022</td>\n",
       "      <td>307.648352</td>\n",
       "      <td>11.161538</td>\n",
       "      <td>97.318681</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime  121609_00010  121607_00095  121610_00300  121612_00301  \\\n",
       "0  2019-04-01      8.822222    316.944444     11.289189     97.361111   \n",
       "1  2019-04-02      8.543750    314.114583     11.205208     96.000000   \n",
       "2  2019-04-03      8.834375    313.635417     11.206250     96.677083   \n",
       "3  2019-04-04      9.365625    311.552083     11.161458     97.552083   \n",
       "4  2019-04-05      9.278022    307.648352     11.161538     97.318681   \n",
       "\n",
       "   121608_00400  243095_99133  243094_99134  \n",
       "0      7.557576           NaN           NaN  \n",
       "1      7.506250           NaN           NaN  \n",
       "2      7.519792           NaN           NaN  \n",
       "3      7.503125           NaN           NaN  \n",
       "4      7.500000           NaN           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the file in S3 bucket that you want to retrieve\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "# retrieve the file and read into a pandas df\n",
    "obj = s3_client.get_object(Bucket=s3_bucket, Key=s3_fpath)\n",
    "df = pd.read_csv(obj.get(\"Body\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of file version available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': 'WSymHRVvZhDELGYs_ycyoKpkH619xf60',\n",
       "  'IsLatest': True,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 21, 57, 4, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': 'qXkbGuRVaNCZ6V8Z5GZN88MBD5h2dOah',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 20, 47, 52, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': 'wK8ZO0s_88AMVzQJegix37X6dXIZCdEh',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 16, 21, 42, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': '35l6y2wEVuYpYn7ap1XscXCIXXeDpHtw',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 16, 20, 16, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': 'U9MW4CfccCqeACE0N32eeJBo2w_Aa1rt',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 16, 18, 35, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': 'ZftrC7SmmOj3K19D3OBy.tI4dM0Cyd5c',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 15, 40, 14, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}},\n",
       " {'ETag': '\"07de0739f00600345b46fa387f74d89a\"',\n",
       "  'Size': 24897,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Key': '00_shared_data/usgs_nwis_01477050_fromfile.csv',\n",
       "  'VersionId': '5fbuoEbyyNdEBLSQzNcGusPS.3sq9F05',\n",
       "  'IsLatest': False,\n",
       "  'LastModified': datetime.datetime(2021, 11, 19, 15, 39, 4, tzinfo=tzutc()),\n",
       "  'Owner': {'DisplayName': 'gs-chs-dev-wma',\n",
       "   'ID': '71818ee6aab503bfe46fc0d15fedb47b628eb41497ecfbc6b80b5096535847f3'}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the file in S3 bucket that you want to get version for\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "# get versions available\n",
    "versions = s3_client.list_object_versions(Bucket=s3_bucket, Prefix=s3_fpath)\n",
    "display(versions.get('Versions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a specific version and save to a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the S3 file and version that you want to retrieve\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "version = '35l6y2wEVuYpYn7ap1XscXCIXXeDpHtw'\n",
    "# definte the local file path that you want to save this file to\n",
    "local_fpath = f'./data/usgs_nwis_01477050_{version}.csv'\n",
    "# retrieve the file\n",
    "s3_client.download_file(s3_bucket, s3_fpath, local_fpath, ExtraArgs={'VersionId': version})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a specific version into a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>121609_00010</th>\n",
       "      <th>121607_00095</th>\n",
       "      <th>121610_00300</th>\n",
       "      <th>121612_00301</th>\n",
       "      <th>121608_00400</th>\n",
       "      <th>243095_99133</th>\n",
       "      <th>243094_99134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>8.822222</td>\n",
       "      <td>316.944444</td>\n",
       "      <td>11.289189</td>\n",
       "      <td>97.361111</td>\n",
       "      <td>7.557576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>8.543750</td>\n",
       "      <td>314.114583</td>\n",
       "      <td>11.205208</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.506250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>8.834375</td>\n",
       "      <td>313.635417</td>\n",
       "      <td>11.206250</td>\n",
       "      <td>96.677083</td>\n",
       "      <td>7.519792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>9.365625</td>\n",
       "      <td>311.552083</td>\n",
       "      <td>11.161458</td>\n",
       "      <td>97.552083</td>\n",
       "      <td>7.503125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>9.278022</td>\n",
       "      <td>307.648352</td>\n",
       "      <td>11.161538</td>\n",
       "      <td>97.318681</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime  121609_00010  121607_00095  121610_00300  121612_00301  \\\n",
       "0  2019-04-01      8.822222    316.944444     11.289189     97.361111   \n",
       "1  2019-04-02      8.543750    314.114583     11.205208     96.000000   \n",
       "2  2019-04-03      8.834375    313.635417     11.206250     96.677083   \n",
       "3  2019-04-04      9.365625    311.552083     11.161458     97.552083   \n",
       "4  2019-04-05      9.278022    307.648352     11.161538     97.318681   \n",
       "\n",
       "   121608_00400  243095_99133  243094_99134  \n",
       "0      7.557576           NaN           NaN  \n",
       "1      7.506250           NaN           NaN  \n",
       "2      7.519792           NaN           NaN  \n",
       "3      7.503125           NaN           NaN  \n",
       "4      7.500000           NaN           NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the S3 file and version that you want to retrieve\n",
    "s3_fpath = '00_shared_data/usgs_nwis_01477050_fromfile.csv'\n",
    "version = '35l6y2wEVuYpYn7ap1XscXCIXXeDpHtw'\n",
    "# retrieve the file and read into a pandas df\n",
    "obj = s3_client.get_object(\n",
    "    Bucket=s3_bucket,\n",
    "    Key=s3_fpath,\n",
    "    VersionId=version,\n",
    ")\n",
    "data = obj.get(\"Body\")\n",
    "df = pd.read_csv(data, encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5945895269787ca017dd2f81b392159e5f0d77fc162da956d59148429b7d75ee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('geo': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
